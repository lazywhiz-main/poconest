import { AIProvider, AIProviderConfig, AIAnalysisResponse, EmbeddingResponse } from './AIProvider';
import { AIRequestContext } from '../openai';
import { supabase } from '../../supabase/client';
import { AIUsageLogger } from '../AIUsageLogger';

export class GeminiProvider implements AIProvider {
  name = 'Gemini';
  private config: AIProviderConfig;

  constructor(config: AIProviderConfig) {
    this.config = {
      model: 'gemini-1.5-pro-latest',
      embeddingModel: 'text-embedding-004', // Geminiã®åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«
      maxTokens: 8192,
      temperature: 0.7,
      ...config,
      name: 'Gemini'
    };
  }

  async isAvailable(): Promise<boolean> {
    try {
      console.log('ğŸ” [GeminiProvider] ai-health-check Edge Functionå‘¼ã³å‡ºã—é–‹å§‹:', {
        functionName: 'ai-health-check',
        timestamp: new Date().toISOString(),
        stackTrace: new Error().stack
      });
      
      const response = await supabase.functions.invoke('ai-health-check', {
        body: { provider: 'gemini' }
      });
      return response.data?.available === true;
    } catch (error) {
      console.warn('[GeminiProvider] Availability check failed:', error);
      return false;
    }
  }

  async generateEmbedding(text: string): Promise<number[] | null> {
    try {
      console.log('ğŸ” [GeminiProvider] ai-embeddings Edge Functionå‘¼ã³å‡ºã—é–‹å§‹:', {
        functionName: 'ai-embeddings',
        timestamp: new Date().toISOString(),
        textLength: text.length,
        stackTrace: new Error().stack
      });
      
      const response = await supabase.functions.invoke('ai-embeddings', {
        body: { 
          text,
          provider: 'gemini',
          model: this.config.embeddingModel
        }
      });

      if (!response.data?.success) {
        throw new Error(response.data?.error || 'Gemini embedding generation failed');
      }

      return response.data.embeddings;
    } catch (error) {
      console.error('[GeminiProvider] Failed to generate embedding:', error);
      return null;
    }
  }

  async generateEmbeddings(texts: string[]): Promise<number[][]> {
    try {
      console.log('ğŸ” [GeminiProvider] ai-embeddings Edge Functionå‘¼ã³å‡ºã—é–‹å§‹:', {
        functionName: 'ai-embeddings',
        timestamp: new Date().toISOString(),
        textsCount: texts.length,
        stackTrace: new Error().stack
      });
      
      const response = await supabase.functions.invoke('ai-embeddings', {
        body: { 
          texts,
          provider: 'gemini',
          model: this.config.embeddingModel
        }
      });

      if (!response.data?.success) {
        throw new Error(response.data?.error || 'Gemini batch embedding generation failed');
      }

      return response.data.embeddings;
    } catch (error) {
      console.error('[GeminiProvider] Failed to generate embeddings:', error);
      return []; // ç©ºé…åˆ—ã‚’è¿”ã™
    }
  }

  async generateSummary(content: string, context?: AIRequestContext): Promise<string> {
    const startTime = Date.now();
    try {
      console.log('ğŸ” [GeminiProvider] generateSummaryå‘¼ã³å‡ºã—é–‹å§‹', {
        timestamp: new Date().toISOString(),
        contentLength: content.length,
        stackTrace: new Error().stack
      });
      
      console.log('ğŸ” [GeminiProvider] ai-summary Edge Functionå‘¼ã³å‡ºã—é–‹å§‹:', {
        functionName: 'ai-summary',
        timestamp: new Date().toISOString(),
        contentLength: content.length,
        stackTrace: new Error().stack
      });
      
      const response = await supabase.functions.invoke('ai-summary', {
        body: {
          action: 'summary',
          content,
          provider: 'gemini',
          model: this.config.model,
          maxTokens: this.config.maxTokens
        }
      });

      console.log('ğŸ” [GeminiProvider] generateSummary Edge Functionå‘¼ã³å‡ºã—å®Œäº†');

      if (!response.data?.success) {
        throw new Error(response.data?.error || 'Summary generation failed');
      }

      // AIä½¿ç”¨é‡ã‚’ãƒ­ã‚°
      if (context) {
        const inputTokens = response.data.usage?.prompt_tokens || Math.ceil(content.length / 4);
        const outputTokens = response.data.usage?.completion_tokens || Math.ceil(response.data.result.length / 4);
        const cost = AIUsageLogger.calculateCost('gemini', this.config.model || 'gemini-1.5-flash', inputTokens, outputTokens);
        
        await AIUsageLogger.logUsage({
          userId: context.userId,
          nestId: context.nestId,
          featureType: 'meeting_summary',
          provider: 'gemini',
          model: this.config.model || 'gemini-1.5-flash',
          inputTokens,
          outputTokens,
          estimatedCostUsd: cost,
          requestMetadata: { contentLength: content.length },
          responseMetadata: { 
            success: true, 
            resultLength: response.data.result.length,
            processingTime: Date.now() - startTime,
            usage: response.data.usage
          },
          meetingId: context.meetingId
        });
      }

      return response.data.result;
    } catch (error) {
      console.error('[GeminiProvider] Failed to generate summary:', error);
      throw error;
    }
  }

  async analyzeChat(messages: any[], systemPrompt: string): Promise<string> {
    try {
      console.log('ğŸ” [GeminiProvider] analyze-chat Edge Functionå‘¼ã³å‡ºã—é–‹å§‹:', {
        functionName: 'analyze-chat',
        timestamp: new Date().toISOString(),
        messagesCount: messages.length,
        stackTrace: new Error().stack
      });
      
      const response = await supabase.functions.invoke('analyze-chat', {
        body: {
          messages,
          systemPrompt,
          provider: 'gemini',
          model: this.config.model,
          maxTokens: this.config.maxTokens,
          temperature: this.config.temperature
        }
      });

      if (!response.data?.success) {
        throw new Error(response.data?.error || 'Gemini chat analysis failed');
      }

      return response.data.markdown || response.data.result;
    } catch (error) {
      console.error('[GeminiProvider] Failed to analyze chat:', error);
      throw error;
    }
  }

  async extractCards(meetingContent: string, meetingId?: string, jobId?: string): Promise<any[]> {
    try {
      // ğŸ”’ job_idãŒç„¡ã„å ´åˆã¯Edge Functionã‚’å‘¼ã³å‡ºã•ãªã„
      if (!jobId) {
        console.log('ğŸš« [GeminiProvider] job_idãŒç„¡ã„ãŸã‚Edge Functionå‘¼ã³å‡ºã—ã‚’ã‚¹ã‚­ãƒƒãƒ—');
        throw new Error('job_idãŒå¿…é ˆã§ã™ã€‚Edge Functionã‚’å‘¼ã³å‡ºã™ã“ã¨ãŒã§ãã¾ã›ã‚“ã€‚');
      }

      console.log('ğŸš¨ğŸš¨ğŸš¨ [GeminiProvider] extractCardså‘¼ã³å‡ºã—é–‹å§‹ - job_idä»˜ãEdge Functionå‘¼ã³å‡ºã— ğŸš¨ğŸš¨ğŸš¨', {
        timestamp: new Date().toISOString(),
        contentLength: meetingContent.length,
        meetingId: meetingId,
        jobId: jobId,
        directCall: jobId ? false : true,
        stackTrace: new Error().stack
      });
      
      // ğŸš¨ ä¸€æ™‚çš„ã«Edge Functionå‘¼ã³å‡ºã—ã‚’ç„¡åŠ¹åŒ–ã—ã¦ãƒ‡ãƒãƒƒã‚°
      console.log('ğŸš¨ğŸš¨ğŸš¨ [GeminiProvider] Edge Functionå‘¼ã³å‡ºã—ã‚’ä¸€æ™‚çš„ã«ç„¡åŠ¹åŒ– ğŸš¨ğŸš¨ğŸš¨');
      throw new Error('GeminiProvider Edge Functionå‘¼ã³å‡ºã—ãŒä¸€æ™‚çš„ã«ç„¡åŠ¹åŒ–ã•ã‚Œã¦ã„ã¾ã™');
    } catch (error) {
      console.error('[GeminiProvider] Failed to extract cards:', error);
      return [];
    }
  }
} 